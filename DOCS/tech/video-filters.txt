First draft on video filter layer by A'rpi
=================================

Main goals:
- it should be in libmpcodecs
- it should reduce number of memcpys and memoru allocation to minimum
- it should do postprocessing, colorspace convert, scale and crop/expand/flip
  [is there any other type of filters? maybe we could generalize these]
- maybe: sub/osd

Implementation:

The video filter plugin should implement the get_image() call (called from
the video decoder) and call get_image() for the destination image.

so, it would have:

optional:
    int get_image(mp_image_t* mpi)   // called through control()

    if the filter doesn't implement this call, the core (vd.c) will alloc
    buffer using memalign() as for disabled direct rendering.

mandatory:
    mp_vfilter_data* init()
    
    void uninit(mp_vfilter_data* vfd)
    
    int control(mp_vfilter_data* vfd, ...)

    mp_image_t* process(mp_vfilter_data* vfd, mp_image_t* mpi,(*get_image)())
    
    this function will receive an mpi (maybe previously returned by get_image())
    and should return the filtered mpi. it should use mpcodecs_get_image() to
    allocate a new mpi.
    the returned mpi may be EXPORT type, so just doing some pointer/stride
    tricks (usually enough for crop/expand/flip) without duplicating the
    image buffer or doing the modifications in the incoming buffer (if its
    type allows it - so no flags PRESERVE/READABLE set)

mp_vfilter_data would be a transparent (to caller) pointer, used by the
filter instance to store its internal data, tables, parameters etc.
it would allow a fliter to be used more than one times in the queue.
for example: resize in 2 step, postproc+resize+postproc, expand+scale+crop etc

the tricky part of these filters is finding and implementing Direct
Filtering(C) using get_image().

anyway, as first step you can skip get_image() implementation, and just
leave it to vd.c core. in most cases it will be enough, direct filtering
only helps with simple filters (crop/expand/flip) in most cases.

